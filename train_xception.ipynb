{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.xception import preprocess_input\n",
    "\n",
    "from xception import get_xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/ubuntu/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25600 images belonging to 256 classes.\n",
      "Found 5120 images belonging to 256 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    data_format='channels_last',\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    data_dir + 'train', \n",
    "    target_size=(299, 299),\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "val_generator = data_generator.flow_from_directory(\n",
    "    data_dir + 'val', \n",
    "    target_size=(299, 299),\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_xception()\n",
    "\n",
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(lr=1e-4), \n",
    "    loss='categorical_crossentropy', metrics=['accuracy', 'top_k_categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "400/400 [==============================] - 205s - loss: 3.7803 - acc: 0.4745 - top_k_categorical_accuracy: 0.6484 - val_loss: 1.9980 - val_acc: 0.7826 - val_top_k_categorical_accuracy: 0.9297\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - 204s - loss: 1.5028 - acc: 0.7947 - top_k_categorical_accuracy: 0.9386 - val_loss: 1.0635 - val_acc: 0.8206 - val_top_k_categorical_accuracy: 0.9473\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - 204s - loss: 0.8996 - acc: 0.8484 - top_k_categorical_accuracy: 0.9615 - val_loss: 0.8329 - val_acc: 0.8320 - val_top_k_categorical_accuracy: 0.9535\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - 204s - loss: 0.6544 - acc: 0.8775 - top_k_categorical_accuracy: 0.9739 - val_loss: 0.7266 - val_acc: 0.8402 - val_top_k_categorical_accuracy: 0.9528\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - 204s - loss: 0.5098 - acc: 0.9024 - top_k_categorical_accuracy: 0.9819 - val_loss: 0.6648 - val_acc: 0.8389 - val_top_k_categorical_accuracy: 0.9567\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - 204s - loss: 0.4047 - acc: 0.9221 - top_k_categorical_accuracy: 0.9880 - val_loss: 0.6352 - val_acc: 0.8483 - val_top_k_categorical_accuracy: 0.9574\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - 204s - loss: 0.3253 - acc: 0.9391 - top_k_categorical_accuracy: 0.9919 - val_loss: 0.6081 - val_acc: 0.8503 - val_top_k_categorical_accuracy: 0.9580\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - 204s - loss: 0.2639 - acc: 0.9524 - top_k_categorical_accuracy: 0.9954 - val_loss: 0.5949 - val_acc: 0.8519 - val_top_k_categorical_accuracy: 0.9590\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - 204s - loss: 0.2161 - acc: 0.9639 - top_k_categorical_accuracy: 0.9965 - val_loss: 0.5808 - val_acc: 0.8555 - val_top_k_categorical_accuracy: 0.9567\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - 204s - loss: 0.1775 - acc: 0.9703 - top_k_categorical_accuracy: 0.9979 - val_loss: 0.5569 - val_acc: 0.8610 - val_top_k_categorical_accuracy: 0.9609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5ce44c3cc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=400, epochs=10, verbose=1,\n",
    "    validation_data=val_generator, validation_steps=48\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5120 images belonging to 256 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator_no_shuffle = data_generator.flow_from_directory(\n",
    "    data_dir + 'val', \n",
    "    target_size=(299, 299),\n",
    "    batch_size=64, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.57773708868771789, 0.85429687499999996, 0.95703125]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(val_generator_no_shuffle, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('xception_weights.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
