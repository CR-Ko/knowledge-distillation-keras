{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from xception import Xception, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/ubuntu/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16980 images belonging to 256 classes.\n",
      "Found 5120 images belonging to 256 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=30, \n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True, \n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.001,\n",
    "    channel_shift_range=0.1,\n",
    "    fill_mode='reflect',\n",
    "    data_format='channels_last',\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "data_generator_val = ImageDataGenerator(\n",
    "    data_format='channels_last',\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    data_dir + 'train_no_resizing', \n",
    "    target_size=(299, 299),\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "val_generator = data_generator_val.flow_from_directory(\n",
    "    data_dir + 'val', shuffle=False,\n",
    "    target_size=(299, 299),\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Xception(weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.SGD(lr=1e-2, momentum=0.9, nesterov=True), \n",
    "    loss='categorical_crossentropy', metrics=['accuracy', 'top_k_categorical_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "266/266 [==============================] - 163s - loss: 3.9762 - acc: 0.3249 - top_k_categorical_accuracy: 0.4612 - val_loss: 3.2910 - val_acc: 0.4666 - val_top_k_categorical_accuracy: 0.7197\n",
      "Epoch 2/30\n",
      "266/266 [==============================] - 161s - loss: 2.2335 - acc: 0.6227 - top_k_categorical_accuracy: 0.8145 - val_loss: 1.8696 - val_acc: 0.6570 - val_top_k_categorical_accuracy: 0.8789\n",
      "Epoch 3/30\n",
      "266/266 [==============================] - 161s - loss: 1.5226 - acc: 0.7112 - top_k_categorical_accuracy: 0.8911 - val_loss: 1.3368 - val_acc: 0.7346 - val_top_k_categorical_accuracy: 0.9189\n",
      "Epoch 4/30\n",
      "266/266 [==============================] - 161s - loss: 1.2231 - acc: 0.7527 - top_k_categorical_accuracy: 0.9124 - val_loss: 1.0939 - val_acc: 0.7707 - val_top_k_categorical_accuracy: 0.9289\n",
      "Epoch 5/30\n",
      "266/266 [==============================] - 161s - loss: 1.0554 - acc: 0.7792 - top_k_categorical_accuracy: 0.9242 - val_loss: 0.9827 - val_acc: 0.7822 - val_top_k_categorical_accuracy: 0.9361\n",
      "Epoch 6/30\n",
      "266/266 [==============================] - 161s - loss: 0.9525 - acc: 0.7920 - top_k_categorical_accuracy: 0.9331 - val_loss: 0.9031 - val_acc: 0.7932 - val_top_k_categorical_accuracy: 0.9414\n",
      "Epoch 7/30\n",
      "266/266 [==============================] - 161s - loss: 0.8914 - acc: 0.7995 - top_k_categorical_accuracy: 0.9387 - val_loss: 0.8727 - val_acc: 0.8002 - val_top_k_categorical_accuracy: 0.9402\n",
      "Epoch 8/30\n",
      "266/266 [==============================] - 161s - loss: 0.8319 - acc: 0.8118 - top_k_categorical_accuracy: 0.9432 - val_loss: 0.8268 - val_acc: 0.8053 - val_top_k_categorical_accuracy: 0.9447\n",
      "Epoch 9/30\n",
      "266/266 [==============================] - 161s - loss: 0.7794 - acc: 0.8232 - top_k_categorical_accuracy: 0.9491 - val_loss: 0.8082 - val_acc: 0.8102 - val_top_k_categorical_accuracy: 0.9441\n",
      "Epoch 10/30\n",
      "266/266 [==============================] - 161s - loss: 0.7413 - acc: 0.8303 - top_k_categorical_accuracy: 0.9529 - val_loss: 0.7862 - val_acc: 0.8133 - val_top_k_categorical_accuracy: 0.9477\n",
      "Epoch 11/30\n",
      "266/266 [==============================] - 161s - loss: 0.7166 - acc: 0.8355 - top_k_categorical_accuracy: 0.9569 - val_loss: 0.7667 - val_acc: 0.8170 - val_top_k_categorical_accuracy: 0.9488\n",
      "Epoch 12/30\n",
      "266/266 [==============================] - 161s - loss: 0.6792 - acc: 0.8450 - top_k_categorical_accuracy: 0.9599 - val_loss: 0.7592 - val_acc: 0.8191 - val_top_k_categorical_accuracy: 0.9492\n",
      "Epoch 13/30\n",
      "266/266 [==============================] - 161s - loss: 0.6620 - acc: 0.8479 - top_k_categorical_accuracy: 0.9629 - val_loss: 0.7417 - val_acc: 0.8229 - val_top_k_categorical_accuracy: 0.9500\n",
      "Epoch 14/30\n",
      "266/266 [==============================] - 161s - loss: 0.6207 - acc: 0.8553 - top_k_categorical_accuracy: 0.9692 - val_loss: 0.7457 - val_acc: 0.8223 - val_top_k_categorical_accuracy: 0.9492\n",
      "Epoch 15/30\n",
      "266/266 [==============================] - 161s - loss: 0.6173 - acc: 0.8518 - top_k_categorical_accuracy: 0.9659 - val_loss: 0.7210 - val_acc: 0.8271 - val_top_k_categorical_accuracy: 0.9520\n",
      "Epoch 16/30\n",
      "266/266 [==============================] - 161s - loss: 0.5821 - acc: 0.8644 - top_k_categorical_accuracy: 0.9711 - val_loss: 0.7388 - val_acc: 0.8229 - val_top_k_categorical_accuracy: 0.9492\n",
      "Epoch 17/30\n",
      "266/266 [==============================] - 161s - loss: 0.5675 - acc: 0.8666 - top_k_categorical_accuracy: 0.9726 - val_loss: 0.7175 - val_acc: 0.8303 - val_top_k_categorical_accuracy: 0.9510\n",
      "Epoch 18/30\n",
      "266/266 [==============================] - 161s - loss: 0.5485 - acc: 0.8706 - top_k_categorical_accuracy: 0.9749 - val_loss: 0.7128 - val_acc: 0.8307 - val_top_k_categorical_accuracy: 0.9525\n",
      "Epoch 19/30\n",
      "266/266 [==============================] - 161s - loss: 0.5297 - acc: 0.8741 - top_k_categorical_accuracy: 0.9764 - val_loss: 0.7083 - val_acc: 0.8299 - val_top_k_categorical_accuracy: 0.9527\n",
      "Epoch 20/30\n",
      "266/266 [==============================] - 161s - loss: 0.5163 - acc: 0.8800 - top_k_categorical_accuracy: 0.9772 - val_loss: 0.7003 - val_acc: 0.8328 - val_top_k_categorical_accuracy: 0.9535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc2655a160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=266, epochs=30, verbose=1,\n",
    "    callbacks=[\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=2, epsilon=0.007),\n",
    "        EarlyStopping(monitor='val_acc', patience=4, min_delta=0.01)\n",
    "    ],\n",
    "    validation_data=val_generator, validation_steps=80, workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.70807909807190295, 0.83027343750000004, 0.953125]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(val_generator, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('xception_weights.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
